# **Pre-requisite**
- Basic understanding of Python and Java
- Basic understanding of Data Engineering

**Total Duration** - 48 Hours. 8 Hours per day
# **Day 1 - Python**
1) Understanding of Python
   1) What is python?
   1) Python documentation and help
1) Python Environment Set-up and Installation
1) Jupyter Notebook Overview
1) Python Basics
   1) Data Types
      1) Numbers
      1) Strings
      1) Print Formatting
      1) Lists
      1) Dictionaries
      1) Booleans
      1) Tuples and Sets
1) Python Operators
1) If, elif and else Statements
1) Loops in Python
1) Errors & Exceptions
   1) Try – except
   1) Assert, Raise
   1) Finally
1) File handling
   1) Syntax
   1) How to Open File
   1) Read Lines
   1) Write to an Existing File
   1) Create a New File
   1) Delete a File
1) Using NumPy Package in Python
   1) Why use NumPy?
   1) Numpy Arrays 
   1) Numpy Array Indexing 
   1) Numpy Array Manipulation
   1) Numpy Operations 
   1) Various useful Numpy functions
   1) Broadcasting
   1) Numpy Statistical Functions
   1) Numpy Mathematical Functions
# **Day 2 - Python**
1) Using Pandas Package in Python
   1) Series 
   1) DataFrames 
   1) Missing Data Treatment
   1) Groupby 
   1) Merging Joining and Concatenating
   1) Read Excel, JSON, XML files
   1) Data Input and Output
1) Python Performance Tuning and Best Practices
1) Python Regex
   1) What is Regex
   1) How to use Regex in Python
   1) Examples of Regex in Python
1) Python - MySQL Database Access
   1) Introduction
   1) Steps for DB API
   1) What is MySQLdb?
   1) How do I Install MySQLdb?
   1) Install MySQLdb
   1) Database Connection
   1) Creating Database Table
   1) INSERT/Read/Update/Delete Operations
1) Debugging in Python



1) Logging in Python
   1) Why Use the logging Module
   1) Creating a Simple Logger
   1) Logging Exceptions
   1) Adding additional LogRecord attributes
   1) Formatted Log Stamp
   1) Table of Logging Levels
   1) Default Logging Level
# **Day 3 - Python**
1) Python Packaging and Virtual Environment
   1) Background of Packaging
   1) Why we need to create Virtual Environment?
   1) Managing Packages with PIP
   1) Installing Packaging in Virtual Environment
      1) Installing PIP on Windows
      1) Installing Virtualenv
      1) Creating Virtual Environment
      1) Activating Virtual Environment
      1) Leaving/Deactivate Virtual Environment
      1) Installing Packages
   1) Using Requirement Files
   1) Freezing Dependencies
   1) Installing packages from Requirements file
1) Deployment of Python Project
   1) Deployment tools
   1) Deployment resources
   1) Deployment learning checklist
   1) Create The Python Application
   1) Push Code to Repository
   1) Create Pipelines Application
   1) Deploy Steps
   1) PreInstall
   1) PostInstall
   1) Re-Build Application
   1) Deploy Application
# **Day 4 - Scala**
1) Understanding of Scala
   1) What is Scala?
   1) Scala documentation and help
1) Scala Environment Set-up and Installation
1) Working with Data
   1) Values
   1) Variables
   1) Naming
   1) Types
      1) Numeric Data Types
      1) Strings
      1) An Overview of Scala Types
      1) Tuples
1) Expressions and Conditionals
   1) Expressions
      1) Defining Values and Variables with Expressions
      1) Expression Blocks
      1) Statements
   1) If..Else Expression Blocks
      1) If Expressions
      1) If-Else Expressions
   1) Match Expressions
      1) Matching with Wildcard Patterns
      1) Matching with Pattern Guards
      1) Matching Types with Pattern Variables



1) Loops
   1) Iterator Guards
   1) Nested Iterators
   1) Value Binding
   1) While and Do/While Loops
1) Functions
   1) Procedures
   1) Functions with Empty Parentheses
   1) Function Invocation with Expression Blocks
   1) Calling Functions with Named Parameters
   1) Parameters with Default Values

# **Day 5 - Apache Spark with Python and Scala**
1) What is Apache Spark
1) Running Spark
   1) Downloading Spark Locally
   1) Launching Spark’s Interactive Consoles
1) An Introduction to Apache Spark
   1) Spark’s Basic Architecture
   1) Spark’s Language APIs
   1) Starting Spark
   1) The SparkSession
   1) DataFrames
      1) Partitions
   1) Transformations
      1) Lazy Evaluation
   1) Actions
1) Spark UI
1) Spark’s Toolset
1) Structured API
   1) DataFrames and Datasets
   1) Schemas
   1) Overview of Structured Spark Types
      1) DataFrames Versus Datasets
      1) Columns
      1) Rows
      1) Spark Types



1) Overview of Structured API Execution
   1) Logical Planning
   1) Physical Planning
   1) Execution
1) Basic Structured Operations
   1) Schemas
   1) Columns and Expressions
   1) Records and Rows
   1) DataFrame Transformations
1) Aggregations
   1) Aggregation Functions
      1) count
      1) min and max
      1) sum
      1) avg
   1) Grouping


# **Day 6 - Apache Spark with Python and Scala**
1) Data Sources
   1) The Structure of the Data Sources API
   1) CSV Files
   1) JSON Files
   1) Advanced I/O Concepts
      1) Splittable File Types and Compression
      1) Reading Data in Parallel
      1) Writing Data in Parallel
      1) Managing File Size
1) Resilient Distributed Datasets (RDDs)
   1) What Are the Low-Level APIs?
   1) About RDDs
      1) Types of RDDs
      1) When to Use RDDs?
   1) Creating RDDs
   1) Manipulating RDDs
   1) Transformations
      1) distinct
      1) filter
      1) map
      1) sort
      1) Random Splits
   1) Actions
      1) reduce
      1) count
      1) first
      1) max and min
      1) take
   1) Saving Files
      1) saveAsTextFile
      1) SequenceFiles
      1) Hadoop Files
1) Performance Tuning
   1) Caching - Concepts, Storage Type, Guidelines
   1) What is Check-pointing?
   1) Check-pointing vs caching
   1) Minimizing Shuffling for Increased Performance
   1) Using Broadcast Variables and Accumulators
   1) General Performance Guidelines
1) Spark Streaming
   1) Introduction and Streaming Basics
   1) Structured Streaming
      1) Continuous Applications
      1) Table Paradigm, Result Table
      1) Steps for Structured Streaming
      1) Sources and Sinks
   1) Consuming Kafka Data
      1) Kafka Overview
      1) Structured Streaming - "Kafka" format
      1) Processing the Stream
PAGE1 **|** Page

